{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import java.util.UUID\n",
    "import org.joda.time.DateTime\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.streaming.dstream.DStream\n",
    "import org.apache.spark.streaming.kafka._\n",
    "import org.apache.spark.sql.{Row, SQLContext}\n",
    "import org.json4s._\n",
    "import org.json4s.jackson.JsonMethods._\n",
    "import org.json4s.ext.JodaTimeSerializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val zookeeper = \"10.100.198.200:2181\"\n",
    "val group = UUID.randomUUID().toString\n",
    "val topic = \"plant-data\"\n",
    "val threads = 2\n",
    "val topicMap = Map(topic -> threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Context erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val ssc = new StreamingContext(sc, Seconds(1))\n",
    "ssc.checkpoint(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einen Kafka-Stream erstellen \n",
    "Die Kafka-Dependency wurde beim Installieren des Kernels angegeben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val values : DStream[(String, String)] = KafkaUtils.createStream(ssc, zookeeper, group, topicMap)\n",
    "val window : DStream[(Option[_], (String, Int))] = values.window(Seconds(5)).map{\n",
    "    case (key, value) => (None, (value, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model eines Datenpunktes - DataPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case class DataPoint(val plantId: String, val timestamp: String, val metric: String, val value: Double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datenpunkte müssen nach Kraftwerk und Metrik gruppiert werden - ansonsten würden wir 10s Mittelwerte über unterschiedliche Datenpunkte berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dpWindow : DStream[(Option[_], (Double, Int))] = window.map{\n",
    "    case (key, (value,count)) => {\n",
    "        implicit val formats = DefaultFormats ++ org.json4s.ext.JodaTimeSerializers.all\n",
    "        val json = parse(value)\n",
    "        val dp = json.extract[DataPoint]\n",
    "        (Some(dp.plantId, dp.metric), (dp.value, count))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die eigentliche Berechnung des Mittelwerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val avgCalc = dpWindow.transform(rdd =>   \n",
    "    rdd.reduceByKey{\n",
    "        case (acc, el) => (acc._1 + el._1, acc._2 + el._2)\n",
    "    }.map {\n",
    "        case (key, (sum, count)) => (key, sum/count)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgCalc.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
